services:
  blackbox-exporter:
    configs:
    - source: prometheus-blackbox-exporter
    deploy:
      replicas: 1
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: blackbox-exporter
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "134217728"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
      placement:
        max_replicas_per_node: 1
    hostname: replica-{{.Task.Slot}}.blackbox-exporter.internal
    image: docker.io/prom/blackbox-exporter:v0.25.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_gwnetwork:
        aliases:
        - blackbox-exporter.internal
        - blackbox-exporter.svc.cluster.local
      public:
        aliases:
        - blackbox-exporter.svc.cluster.local
  cadvisor:
    cap_add:
    - SYSLOG
    command:
    - -docker_only
    deploy:
      mode: global
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: cadvisor
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "268435456"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
    hostname: replica-{{.Task.Slot}}.cadvisor.internal
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_gwnetwork: null
    ports:
    - mode: host
      target: 8080
      published: 18080
    volumes:
    - type: bind
      source: /
      target: /rootfs
      read_only: true
    - type: bind
      source: /sys
      target: /sys
      read_only: true
    - type: bind
      source: /var/lib/docker
      target: /var/lib/docker
      read_only: true
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
    - type: bind
      source: /dev/kmsg
      target: /dev/kmsg
      read_only: true
  grafana:
    command:
    - echo
    - Initializing Grafana
    deploy:
      replicas: 1
      restart_policy:
        condition: none
      placement:
        constraints:
        - node.role == manager
        max_replicas_per_node: 1
    image: alpine:latest
  grafana-dashboard-provider:
    command:
    - --output-ext=json
    - --output-dir=/grafana-dashboards.d
    - --prometheus-scrape-config-label=io.grafana.dashboard
    configs:
    - source: gf-dashboard-promstack-grafana-metrics
    - source: gf-dashboard-promstack-prometheus-stats
    - source: gf-dashboard-promstack-prometheus-stats-v2
    - source: gf-dashboard-promstack-dockerswarm-nodes
    - source: gf-dashboard-promstack-dockerswarm-services
    - source: gf-dashboard-promstack-cadvisor
    - source: gf-dashboard-promstack-node-exporter
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_grafana == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: grafana-dashboards
      target: /grafana-dashboards.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  grafana-provisioning-alerting-provider:
    command:
    - --output-dir=/grafana-provisioning-alerting.d
    - --prometheus-scrape-config-label=io.grafana.provisioning.alerting
    configs:
    - source: gf-dashboard-promstack-grafana-metrics
    - source: gf-dashboard-promstack-prometheus-stats
    - source: gf-dashboard-promstack-prometheus-stats-v2
    - source: gf-dashboard-promstack-dockerswarm-nodes
    - source: gf-dashboard-promstack-dockerswarm-services
    - source: gf-dashboard-promstack-cadvisor
    - source: gf-dashboard-promstack-node-exporter
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_grafana == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: grafana-provisioning-alerting
      target: /grafana-provisioning-alerting.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  grafana-provisioning-config-reloader:
    depends_on:
    - grafana
    - grafana-dashboard-provider
    - grafana-provisioning-dashboard-provider
    - grafana-provisioning-datasource-provider
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
        order: start-first
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_grafana_server == true
    environment:
      GF_PATHS_PROVISIONING: /etc/grafana/provisioning
      GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
      GF_SECURITY_ADMIN_USER: ${GF_SECURITY_ADMIN_USER}
      GF_SERVER_DOMAIN: replica-{{.Node.ID}}.grafana.internal
    image: docker.io/swarmlibs/grafana-provisioning-config-reloader:0.1.0-rc.3
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      grafana: null
    volumes:
    - type: volume
      source: grafana-provisioning-config-reloader
      target: /data
    - type: volume
      source: grafana-provisioning-alerting
      target: /etc/grafana/provisioning/alerting
    - type: volume
      source: grafana-provisioning-dashboards
      target: /etc/grafana/provisioning/dashboards
    - type: volume
      source: grafana-provisioning-datasources
      target: /etc/grafana/provisioning/datasources
      read_only: true
  grafana-provisioning-dashboard-provider:
    command:
    - --output-dir=/grafana-provisioning-dashboards.d
    - --prometheus-scrape-config-label=io.grafana.provisioning.dashboard
    configs:
    - source: gf-dashboard-promstack-grafana-metrics
    - source: gf-dashboard-promstack-prometheus-stats
    - source: gf-dashboard-promstack-prometheus-stats-v2
    - source: gf-dashboard-promstack-dockerswarm-nodes
    - source: gf-dashboard-promstack-dockerswarm-services
    - source: gf-dashboard-promstack-cadvisor
    - source: gf-dashboard-promstack-node-exporter
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_grafana == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: grafana-provisioning-dashboards
      target: /grafana-provisioning-dashboards.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  grafana-provisioning-datasource-provider:
    command:
    - --output-dir=/grafana-provisioning-datasources.d
    - --prometheus-scrape-config-label=io.grafana.provisioning.datasource
    configs:
    - source: gf-provisioning-datasource-prometheus
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_grafana == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: grafana-provisioning-datasources
      target: /grafana-provisioning-datasources.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  grafana-server:
    configs:
    - source: gf-server-entrypoint
      target: /docker-entrypoint-shim.sh
      mode: 365
    - source: gf-provisioning-dashboards
      target: /etc/grafana/provisioning/dashboards/gf-provisioning-dashboards.yml
    deploy:
      mode: global
      labels:
        io.prometheus.enabled: "true"
        io.prometheus.job_name: grafana
        io.prometheus.scrape_port: "3000"
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
      placement:
        constraints:
        - node.labels.services.promstack_grafana_provisioning_alerting_provider ==
          true
        - node.labels.services.promstack_grafana_provisioning_dashboard_provider ==
          true
        - node.labels.services.promstack_grafana_provisioning_datasource_provider
          == true
    entrypoint:
    - /docker-entrypoint-shim.sh
    environment:
      GF_DATABASE_CACHE_MODE: shared
      GF_DATABASE_WAL: "true"
      GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
      GF_SECURITY_ADMIN_USER: ${GF_SECURITY_ADMIN_USER}
      GF_SERVER_DOMAIN: ${GF_SERVER_DOMAIN}
      GF_SERVER_PROTOCOL: ${GF_SERVER_PROTOCOL}
      GF_SERVER_ROOT_URL: ${GF_SERVER_ROOT_URL}
      GF_SMTP_ENABLED: null
      GF_SMTP_FROM_ADDRESS: null
      GF_SMTP_FROM_NAME: null
      GF_SMTP_HOST: null
      GF_SMTP_PASSWORD: null
      GF_SMTP_SKIP_VERIFY: null
      GF_SMTP_USER: null
      GF_SNAPSHOTS_EXTERNAL_SNAPSHOT_NAME: ${GF_SNAPSHOTS_EXTERNAL_SNAPSHOT_NAME}
      GF_SNAPSHOTS_EXTERNAL_SNAPSHOT_URL: ${GF_SNAPSHOTS_EXTERNAL_SNAPSHOT_URL}
      GRAFANA_UNIFIED_ALERTING_INTERFACE: eth2
    extra_hosts:
    - host.docker.internal:host-gateway
    hostname: replica-{{.Node.ID}}.grafana.internal
    healthcheck:
      test:
      - CMD-SHELL
      - wget -qO - --tries=1 --spider http://127.0.0.1:3000/api/health || exit 1
      timeout: 10s
      interval: 30s
      retries: 3
      start_period: 30s
    image: docker.io/grafana/grafana:11.3.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      grafana:
        aliases:
        - grafana.internal
      prometheus: null
      prometheus_gwnetwork: null
      public:
        aliases:
        - grafana.svc.cluster.local
    ports:
    - target: 3000
      published: 3000
      protocol: tcp
    volumes:
    - type: volume
      source: grafana-data
      target: /var/lib/grafana
    - type: volume
      source: grafana-logs
      target: /var/log/grafana
    - type: volume
      source: grafana-dashboards
      target: /etc/grafana/dashboards
    - type: volume
      source: grafana-provisioning-alerting
      target: /etc/grafana/provisioning/alerting
    - type: volume
      source: grafana-provisioning-dashboards
      target: /etc/grafana/provisioning/dashboards
    - type: volume
      source: grafana-provisioning-datasources
      target: /etc/grafana/provisioning/datasources
  manager-api-proxy:
    command:
    - caddy
    - run
    - --config
    - /etc/caddy/Caddyfile
    configs:
    - source: manager-api-proxy-config
      target: /etc/caddy/Caddyfile
    deploy:
      mode: global
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: manager-api-proxy
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "134217728"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
      placement:
        constraints:
        - node.role == manager
    hostname: manager-api-proxy.docker.internal
    image: caddy:2.8-alpine
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_gwnetwork: null
    user: "0:0"
    volumes:
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  node-exporter:
    command:
    - --path.rootfs=/rootfs
    - --collector.textfile.directory=/etc/node-exporter
    - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
    - --no-collector.ipvs
    configs:
    - source: node-exporter-node-meta
      target: /etc/node-exporter/node_meta.prom
    deploy:
      mode: global
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: node-exporter
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "134217728"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
    hostname: replica-{{.Task.Slot}}.node-exporter.internal
    healthcheck:
      test:
      - CMD-SHELL
      - wget -qO - --tries=1 --spider http://127.0.0.1:9100 || exit 1
      timeout: 10s
      interval: 30s
      retries: 3
      start_period: 30s
    image: docker.io/prom/node-exporter:v1.8.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_gwnetwork: null
    ports:
    - mode: host
      target: 9100
      published: 19100
    volumes:
    - type: bind
      source: /
      target: /rootfs
      read_only: true
  prometheus:
    command:
    - --verbose
    - --file=/run/configs/prometheus.yml.tmpl
    - --out=/prometheus-configs.d/prometheus.yml
    configs:
    - source: prometheus-config-tmpl
      target: /run/configs/prometheus.yml.tmpl
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_prometheus_server == true
    environment:
      PROMETHEUS_ALERTMANAGER_ADDR: ${PROMETHEUS_ALERTMANAGER_ADDR:-tasks.grafana.internal}
      PROMETHEUS_ALERTMANAGER_PORT: ${PROMETHEUS_ALERTMANAGER_PORT:-9094}
      PROMETHEUS_CLUSTER_NAME: ${PROMETHEUS_CLUSTER_NAME:-{{ index .Service.Labels
        "com.docker.stack.namespace"}}}
      PROMETHEUS_CLUSTER_REPLICA: ${PROMETHEUS_CLUSTER_REPLICA:-replica-{{.Task.Slot}}}
    image: docker.io/swarmlibs/genconfig:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    stop_grace_period: 5s
    volumes:
    - type: volume
      source: prometheus-configs
      target: /prometheus-configs.d
  prometheus-config-reloader:
    configs:
    - source: prometheus-config-reloader-entrypoint
      target: /docker-entrypoint-shim.sh
      mode: 365
    depends_on:
    - prometheus
    - prometheus-server
    - prometheus-scrape-config-provider
    deploy:
      mode: global
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.enabled: "true"
        io.prometheus.job_name: prometheus-config-reloader
        io.prometheus.role: prometheus-config-reloader
        io.prometheus.scrape_port: "8080"
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 30s
        window: 15s
      placement:
        constraints:
        - node.labels.services.promstack_prometheus_server == true
    entrypoint:
    - /docker-entrypoint-shim.sh
    environment:
      PROMETHEUS_HOST: replica-{{.Node.ID}}.prometheus.internal
      RELOADER_CONFIG_FILE: /prometheus-configs.d/prometheus.yml
      RELOADER_RELOAD_TIMEOUT: 10s
      RELOADER_WATCH_DIR: /prometheus-configs.d
      RELOADER_WATCH_INTERVAL: 15s
    image: quay.io/prometheus-operator/prometheus-config-reloader:v0.74.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_internal: null
    volumes:
    - type: volume
      source: prometheus-configs
      target: /prometheus-configs.d
  prometheus-federated:
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --storage.tsdb.path=/prometheus
    - --storage.tsdb.retention.time=15d
    - --web.page-title=Prometheus Server Federated - Promstack
    - --web.console.libraries=/usr/share/prometheus/console_libraries
    - --web.console.templates=/usr/share/prometheus/consoles
    - --log.level=info
    configs:
    - source: prometheus-federated-config-tmpl
      target: /etc/prometheus/prometheus.yml
    - source: prometheus-federated-cadvisor
      target: /etc/prometheus/scrape-configs/cadvisor.yml
    - source: prometheus-federated-docker
      target: /etc/prometheus/scrape-configs/docker.yml
    - source: prometheus-federated-dockerswarm-services
      target: /etc/prometheus/scrape-configs/dockerswarm-services.yml
    - source: prometheus-federated-node_exporter
      target: /etc/prometheus/scrape-configs/node_exporter.yml
    - source: prometheus-federated-prometheus
      target: /etc/prometheus/scrape-configs/prometheus.yml
    deploy:
      mode: global
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: prometheus-federated
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "1073741824"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
    environment:
      DOCKERSWARM_NODE_HOSTNAME: '{{.Node.Hostname}}'
      DOCKERSWARM_NODE_ID: '{{.Node.ID}}'
      PROMETHEUS_AGENT_CLUSTER_REPLICA: '{{ index .Service.Labels "com.docker.stack.namespace"}}'
    extra_hosts:
    - host.docker.internal:host-gateway
    hostname: replica-{{.Task.Slot}}.federated.prometheus.internal
    healthcheck:
      test:
      - CMD-SHELL
      - wget -qO - --tries=1 --spider http://127.0.0.1:9090/-/healthy || exit 1
      timeout: 10s
      interval: 30s
      retries: 3
      start_period: 30s
    image: docker.io/prom/prometheus:v3.0.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus_gwnetwork: null
    ports:
    - mode: host
      target: 9090
      published: 19090
    user: "0:0"
    volumes:
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
    - type: volume
      source: prometheus-federated-data
      target: /prometheus
  prometheus-rule-provider:
    command:
    - --output-dir=/prometheus-configs.d/rules
    - --prometheus-scrape-config-label=io.prometheus.rule
    configs:
    - source: prometheus-dockerswarm-nodes-rule
    - source: prometheus-dockerswarm-services-rule
    deploy:
      mode: global
      labels:
        io.prometheus.role: prometheus-config-provider
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_prometheus_server == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: prometheus-configs
      target: /prometheus-configs.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  prometheus-scrape-config-provider:
    command:
    - --output-dir=/prometheus-configs.d/scrape-configs
    configs:
    - source: prometheus-federated
    - source: prometheus-prometheus
    deploy:
      mode: global
      labels:
        io.prometheus.role: prometheus-config-provider
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "67108864"
      restart_policy:
        condition: any
        delay: 15s
        window: 10s
      placement:
        constraints:
        - node.labels.services.promstack_prometheus_server == true
    image: docker.io/swarmlibs/prometheus-config-provider:0.1.0-rc.1
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    volumes:
    - type: volume
      source: prometheus-configs
      target: /prometheus-configs.d
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
  prometheus-server:
    command:
    - --enable-feature=native-histograms
    - --config.file=/prometheus-configs.d/prometheus.yml
    - --storage.tsdb.path=/prometheus
    - --storage.tsdb.retention.time=182d
    - --web.page-title=Prometheus Server - Promstack
    - --web.console.libraries=/usr/share/prometheus/console_libraries
    - --web.console.templates=/usr/share/prometheus/consoles
    - --web.enable-lifecycle
    - --web.enable-remote-write-receiver
    - --log.level=info
    depends_on:
    - prometheus
    deploy:
      replicas: 1
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: prometheus
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
      placement:
        constraints:
        - node.role == manager
        max_replicas_per_node: 1
    extra_hosts:
    - host.docker.internal:host-gateway
    hostname: replica-{{.Node.ID}}.prometheus.internal
    healthcheck:
      test:
      - CMD-SHELL
      - wget -qO - --tries=1 --spider http://127.0.0.1:9090/-/healthy || exit 1
      timeout: 10s
      interval: 30s
      retries: 3
      start_period: 30s
    image: docker.io/prom/prometheus:v3.0.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      grafana:
        aliases:
        - prometheus.svc.cluster.local
      prometheus:
        aliases:
        - prometheus.internal
        - prometheus.svc.cluster.local
      prometheus_gwnetwork:
        aliases:
        - prometheus.internal
        - prometheus.svc.cluster.local
      prometheus_internal:
        aliases:
        - prometheus.internal
      public:
        aliases:
        - prometheus.svc.cluster.local
    ports:
    - target: 9090
      published: 9090
      protocol: tcp
    user: "0:0"
    volumes:
    - type: bind
      source: /var/run/docker.sock
      target: /var/run/docker.sock
      read_only: true
    - type: volume
      source: prometheus-configs
      target: /prometheus-configs.d
    - type: volume
      source: prometheus
      target: /prometheus
  pushgateway:
    configs:
    - source: prometheus-pushgateway
    deploy:
      replicas: 1
      labels:
        io.prometheus.dockerswarm-services.should_be_probed: "false"
        io.prometheus.dockerswarm-tasks.should_be_scraped: "false"
        io.prometheus.role: pushgateway
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      rollback_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 15s
        max_failure_ratio: 0.2
      resources:
        limits:
          memory: "134217728"
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 15
        window: 15s
      placement:
        max_replicas_per_node: 1
    hostname: replica-{{.Task.Slot}}.pushgateway.internal
    image: docker.io/prom/pushgateway:v1.10.0
    logging:
      driver: json-file
      options:
        max-file: "5"
        max-size: 12m
    networks:
      prometheus:
        aliases:
        - pushgateway.svc.cluster.local
      prometheus_gwnetwork:
        aliases:
        - pushgateway.internal
        - pushgateway.svc.cluster.local
networks:
  grafana: {}
  prometheus:
    name: prometheus
    external: true
  prometheus_gwnetwork:
    name: prometheus_gwnetwork
    external: true
  prometheus_internal:
    internal: true
  public:
    name: public
    external: true
volumes:
  grafana-dashboards: {}
  grafana-data: {}
  grafana-logs: {}
  grafana-provisioning-alerting: {}
  grafana-provisioning-config-reloader: {}
  grafana-provisioning-dashboards: {}
  grafana-provisioning-datasources: {}
  prometheus: {}
  prometheus-configs: {}
  prometheus-federated-data: {}
configs:
  gf-dashboard-promstack-cadvisor:
    name: gf-dashboard-promstack-cadvisor-v1
    file: ./grafana/grafana/dashboards/promstack-cadvisor.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-dockerstack:
    name: gf-dashboard-promstack-dockerstack-v1
    file: ./grafana/grafana/dashboards/promstack-dockerstack.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-dockerswarm-nodes:
    name: gf-dashboard-promstack-dockerswarm-nodes-v1
    file: ./grafana/grafana/dashboards/promstack-dockerswarm-nodes.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-dockerswarm-services:
    name: gf-dashboard-promstack-dockerswarm-services-v1
    file: ./grafana/grafana/dashboards/promstack-dockerswarm-services.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-grafana-metrics:
    name: gf-dashboard-promstack-grafana-metrics-v1
    file: ./grafana/grafana/dashboards/promstack-grafana-metrics.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-node-exporter:
    name: gf-dashboard-promstack-node-exporter-v1
    file: ./grafana/grafana/dashboards/promstack-node-exporter.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-prometheus-stats:
    name: gf-dashboard-promstack-prometheus-stats-v1
    file: ./grafana/grafana/dashboards/promstack-prometheus-stats.json
    labels:
      io.grafana.dashboard: "true"
  gf-dashboard-promstack-prometheus-stats-v2:
    name: gf-dashboard-promstack-prometheus-stats-v2
    file: ./grafana/grafana/dashboards/promstack-prometheus-2-0-stats.json
    labels:
      io.grafana.dashboard: "true"
  gf-provisioning-dashboards:
    name: gf-provisioning-dashboards-v1
    file: ./grafana/grafana/provisioning/dashboards/grafana-dashboards.yml
  gf-provisioning-datasource-prometheus:
    name: gf-provisioning-datasource-prometheus-v1
    file: ./grafana/grafana/provisioning/datasources/prometheus.yml
    labels:
      io.grafana.provisioning.datasource: "true"
  gf-server-entrypoint:
    name: gf-server-entrypoint-v1
    file: ./grafana/grafana/docker-entrypoint-shim.sh
  manager-api-proxy-config:
    name: manager-api-proxy-config-v1
    file: ./manager-api-proxy/configs/Caddyfile
  node-exporter-node-meta:
    name: node-exporter-node-meta-v1
    file: ./node-exporter/node_meta.prom
  prometheus-blackbox-exporter:
    name: prometheus-blackbox-exporter-v1
    file: ./blackbox-exporter/prometheus/blackbox-exporter.yml
    labels:
      io.prometheus.scrape_config: "true"
  prometheus-config-reloader-entrypoint:
    name: prometheus-config-reloader-entrypoint-v1
    file: ./prometheus/prometheus-config-reloader/docker-entrypoint-shim.sh
  prometheus-config-tmpl:
    name: prometheus-config-tmpl-v1
    file: ./prometheus/prometheus/prometheus.yml.tmpl
  prometheus-dockerswarm-nodes-rule:
    name: prometheus-dockerswarm-nodes-rule-v1
    file: ./prometheus/prometheus/rules/dockerswarm-nodes.yml
    labels:
      io.prometheus.rule: "true"
  prometheus-dockerswarm-services-rule:
    name: prometheus-dockerswarm-services-rule-v1
    file: ./prometheus/prometheus/rules/dockerswarm-tasks.yml
    labels:
      io.prometheus.rule: "true"
  prometheus-federated:
    name: prometheus-federated-v1
    file: ./prometheus/prometheus/scrape-configs/prometheus-federated.yml
    labels:
      io.prometheus.scrape_config: "true"
  prometheus-federated-cadvisor:
    name: prometheus-federated-cadvisor-v1
    file: ./prometheus-federated/prometheus/scrape-configs/cadvisor.yml
    template_driver: golang
  prometheus-federated-config-tmpl:
    name: prometheus-federated-config-tmpl-v1
    file: ./prometheus-federated/prometheus/prometheus.yml.tmpl
    template_driver: golang
  prometheus-federated-docker:
    name: prometheus-federated-docker-v1
    file: ./prometheus-federated/prometheus/scrape-configs/docker.yml
  prometheus-federated-dockerswarm-services:
    name: prometheus-federated-dockerswarm-services-v1
    file: ./prometheus-federated/prometheus/scrape-configs/dockerswarm-services.yml
    template_driver: golang
  prometheus-federated-node_exporter:
    name: prometheus-federated-node_exporter-v1
    file: ./prometheus-federated/prometheus/scrape-configs/node_exporter.yml
    template_driver: golang
  prometheus-federated-prometheus:
    name: prometheus-federated-prometheus-v1
    file: ./prometheus-federated/prometheus/scrape-configs/prometheus.yml
  prometheus-prometheus:
    name: prometheus-prometheus-v1
    file: ./prometheus/prometheus/scrape-configs/prometheus.yml
    labels:
      io.prometheus.scrape_config: "true"
  prometheus-pushgateway:
    name: prometheus-pushgateway-v1
    file: ./pushgateway/prometheus/pushgateway.yml
    labels:
      io.prometheus.scrape_config: "true"
x-default-logging:
  driver: json-file
  options:
    max-file: "5"
    max-size: 12m
x-exporter-resources-constraints:
  limits:
    memory: 128M
